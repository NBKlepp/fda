
//::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** @author  John Miller
 *  @version 1.2
 *  @date    Tue May 29 14:45:32 EDT 2012
 *  @see     LICENSE (MIT style license file).
 */

package scalation.analytics

import scala.collection.mutable.Set
import scala.util.control.Breaks.{breakable, break}

import scalation.linalgebra.{MatrixD, VectorD}
import scalation.random.{Randi, Uniform}
import scalation.util.{banner, Error}

import com.opencsv.CSVWriter
import java.io.{FileWriter,File}

import scala.math.exp
//:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** The `KMeansClustering` class cluster several vectors/points using k-means
 *  clustering.  Either (1) randomly assign points to 'k' clusters or (2) randomly
 *  pick 'k' points as initial centroids (technique (1) to work better and is the
 *  primary technique).  Iteratively, reassign each point to the cluster containing
 *  the closest centroid.  Stop when there are no changes to the clusters.
 *  @param x        the vectors/points to be clustered stored as rows of a matrix
 *  @param k        the number of clusters to make
 *  @param s        the random number stream (to vary the clusters made)
 *  @param primary  true indicates use the primary technique for initiating the clustering
 */
class KMeansClustering (x: MatrixD, k: Int, s: Int = 0, primary: Boolean = true)
      extends Clusterer with Error
{
    if (k >= x.dim1) flaw ("constructor", "k must be less than the number of vectors")

    private val DEBUG    = true                          // debug flag
    private val MAX_ITER = 200                           // the maximum number of iterations
    private val cent     = new MatrixD (k, x.dim2)       // the k centroids of clusters
    private val clustr   = Array.ofDim [Int] (x.dim1)    // assignment of vectors to clusters
    private val dist     = new VectorD (x.dim1)          // distance to closest centroid
    dist.set (Double.PositiveInfinity)

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Compute a distance metric between vectors/points u and v.
     *  @param u  the first vector/point
     *  @param v  the second vector/point
     */
    def distance (u: VectorD, v: VectorD): Double =
    {
        (u - v).normSq       // squared Euclidean norm used for efficiency, may use other norms
    } // distance

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Assign each vector/point to a random cluster.  Primary technique for
     *  initiating the clustering.
     */
    def assign ()
    {
        val ran = new Randi (0, k - 1, s)              // for random integers: 0, ..., k-1
        for (i <- x.range1) clustr(i) = ran.igen       // randomly assign to a cluster
    } // assign

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Reassign each vector/point to the cluster with the closest centroid.
     *  Indicate done, if no points changed clusters (for stopping rule).
     */
    def reassign (): Boolean =
    {
        var done = true                                // done indicates no changes
        for (i <- x.range1) {
            val v = x(i)                               // let v be the ith vector
            for (c <- 0 until k) {
                val newDist = distance (v, cent(c))    // calc distance to centroid c
                if (newDist < dist(i)) {               // is it closer than old distance
                    dist(i)  = newDist                 // make it the new distance
                    clustr(i) = c                      // assign vector i to cluster c
                    done = false                       // changed clusters => not done
                } // if
            } // for
        } // for
        done                                           // return whether there were no changes
    } // reassign

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Randomly pick vectors/points to serve as the initial k centroids (cent).
     *  Secondary technique for initiating the clustering.
     */
    def pickCentroids ()
    {
        val ran  = new Randi (0, x.dim1 - 1, s)        // for random integers: 0, ..., x.dim1-1
        val iSet = Set [Int] ()                        // set of integers already generated
        for (c <- 0 until k) {
            var i = ran.igen                           // generate a random integer
            while (iSet contains i) i = ran.igen       // do not allow repeats
            iSet   += i                                // add to set of generated integers
            cent(c) = x(i)                             // let centroid c be the ith vector
        } // for
    } // pickCentroids

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Calculate the centroids based on current assignment of points to clusters.
     */
    def calcCentroids ()
    {
        val cx = new MatrixD (k, x.dim2)               // to hold sum of vectors for each cluster
        val cs = new VectorD (k)                       // to hold number of vectors in each cluster
        for (i <- x.range1) {
            val ci  = clustr(i)                        // x(i) currently assigned to cluster ci
            cx(ci)  = cx(ci) + x(i)                    // add the next vector in cluster
            cs(ci) += 1.0                              // add 1 to number in cluster
        } // for
        for (c <- 0 until k) cent(c) = cx(c) / cs(c)   // divide to get averages/means
    } // calcCentroids

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Iteratively recompute clusters until the assignment of points does not
     *  change, returning the final cluster assignment vector.
     */
    def cluster (): Array [Int] =
    {
        if (primary) {
            assign ()                                  // randomly assign points to clusters
            calcCentroids ()                           // calculate the initial centroids
        } else {
            pickCentroids ()                           // alt., pick points for initial centroids 
        } // if
        println ("(" + 0 + ") clustr = " + clustr.deep)
        println ("(" + 0 + ") cent   = " + cent)

        breakable { for (l <- 1 to MAX_ITER) {
            if (reassign ()) break                     // reassign points to clusters (no change => break)
            calcCentroids ()                           // re-calculate the centroids
            if (DEBUG) {
                println ("(" + l + ") clustr = " + clustr.deep)
                println ("(" + l + ") cent   = " + cent)
            } // if
        } // for
	}
	
        clustr                                         // return the cluster assignment vector
    } // cluster

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Given a new point/vector 'y', determine which cluster it belongs to,
     *  i.e., the cluster whose centroid it is closest to.
     *  @param y  the vector to classify
     */
    def classify (y: VectorD): Int =
    {
        var dist = distance (y, cent(0))               // calc distance to centroid 0
        var clus = 0                                   // assign y to cluster 0
        for (c <- 1 until k) {
            val newDist = distance (y, cent(c))        // calc distance to centroid c
            if (newDist < dist) {                      // is it closer than old distance
                dist = newDist                         // make it the new distance
                clus = c                               // assign y to cluster c
            } // if
        } // for
        clus                                           // return cluster y belongs to
    } // classify

    //::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Return the sum of pairwise distances for all points in cluster 'r'
     *  @param r  the cluster of interest
     */

    def d(r: Int): Double =
    {
	var sum = 0.0
	for (i <- 0 until x.dim1 if clustr(i)==r;					//filter out non-cluster partners
	     j <- 0 until x.dim1 if clustr(j)==r ) sum += distance( x(i) , x(j) )	//aggregate the pairwise distances
	sum
    } // d

    //::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Return the pooled within cluster sum of squares around the cluster
    *   means. 
    */

    def w(): Double =
    {
	var sum = 0.0
	for( r <- 0 until k ){
	     if(clustr.count(_ == r) != 0) sum += d(r) / (2 * clustr.count(_ == r) )		// calculate the pooled w/in cluster...
	} // for
	sum
    } // w

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Return the pooled within-cluster sum of squares around the cluster means
     *   of a simulated distribution. 
     */

    def wStar(): Double =
    {
	//println(s"x: ${x}")
	var max = Double.MinValue
	var min = Double.MaxValue
	
	var uniDist = new MatrixD(x.dim1, x.dim2)
	for( j <- 0 until x.dim2 ){	
		for( i <- 0 until x.dim1 ){
			if( x(i,j) > max ) max = x(i,j)
			if( x(i,j) < min ) min = x(i,j)
		} // for
		//println(s"max: $max, min: $min")
		val rand2 = new Uniform(min,max,(System.currentTimeMillis()%1000).toInt)
		for( i <- 0 until x.dim1 ) uniDist(i, j) = rand2.gen
		max = Double.MinValue;
		min = Double.MaxValue;
	} // for
	
	//println("uniDist: " + uniDist)
	
	val cl = new KMeansClustering(uniDist, k, s, primary)
	cl.cluster()
	cl.w()
    } // wStar

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /**Return a tuple (gapK, sk) containing the estimated gap statistic for this
     * clustering in position one and the sk in position two.
     * @param B  the number of uniform distributions used to calculate the gap.
     */

    def gap(B: Int = 10): (Double,Double,Double,Double) =
    {
	import math.log
	import math.pow
	var gapK   = 0.0								// the four parts of the tuple
	var lBar   = 0.0
	var sdk    = 0.0
	var sk     = 0.0
	var wStars = Array.ofDim[Double](B)					// an array to hold w* values

	//var wStars = Array(16.27096424, 15.43820423, 15.16485494, 14.86165803, 14.56780082, 14.32199633,14.17995563 ,14.05918976 ,13.9388497 ,13.81926753).map(exp(_))
	//var wVals  = Array(16.07497015 ,15.04521110 ,14.64738577 ,14.39325503 ,14.19861336 ,13.98923129 ,13.80730824 ,13.73746283 ,13.5972341 ,13.49486803)map(exp(_))
	
	for (b <- 0 until B) {
	
		wStars(b)  = wStar()						// repeat w* b many times for the monte carlo simulation		
		lBar      += log( wStars(b) )					// aggregate the results for later computation
		// previously gapK += ...	
	} // for
	//gapK = log(wStars(k-1))
	lBar /= B	// previously gapK /= B					// this gives us the estimated expected value
	//lBar = gapk //log (wStars(k-1))  								
	gapK = lBar-log(w()) //log(wVals(k-1)) //log ( wVals(k-1) )		// this gives us the diff btwn the est. exp. value and the observed (i.e. - gap)
	for ( b <- 0 until B) sdk += pow( log( wStars(b) ) - lBar , 2 )		// finding the standard deviation

	sdk /= B     	      	     	       		     	      		//
	sdk = pow( sdk, 0.5 )
	//sk = sdk * pow( (1 + 1.0/B) , 0.5)          //is this correct? The paper notation confused me...
	sk = pow((1 + 1.0/B) , 0.5)          //is this correct? The paper notation confused me...
	sk *= sdk
	(log(w()),lBar, gapK, sk)
	//(gapK,  sk, lBar, log(w()) ) //log(wVals(k-1)))
	//(log(wVals(k-1)),lBar, gapK, sk)
	
    } // gap

    	
} // KMeansClustering class



//:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** The `KMeansClusteringTest` object is used to test the `KMeansClustering` class.
 *  > run-main scalation.analytics.KMeansClusteringTest
 */
object KMeansClusteringTest extends App
{
    val v = new MatrixD ((6, 2), 1.0, 2.0,
                                 2.0, 1.0,
                                 5.0, 4.0,
                                 4.0, 5.0,
                                 9.0, 8.0,
                                 8.0, 9.0)
    val y = VectorD (10.0, 10.0)
    println ("v = " + v)
    println ("y = " + y)
    println ("----------------------------------------------------")

    for (s <- 0 to 4) {                         // test with different random streams
        banner ("KMeansClustering for stream s = " + s)
        val cl = new KMeansClustering (v, 3, s)                 
        println ("--- final cluster = " + cl.cluster ().deep + "\n")
        println ("--- classify " + y + " = " + cl.classify (y) + "\n")
    } // for

    

} // KMeansClusteringTest object


//:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** The `KMeansClusteringTest2` object is used to test the wStar() and Gap()
 *  statistic methods of the `KMeansClustering` class.
 *  > run-main scalation.analytics.KMeansClusteringTest2
 */
object KMeansClusteringTest2 extends App
{
    val v = new MatrixD ((6, 2), 1.0, 2.0,
                                 2.0, 1.0,
                                 5.0, 4.0,
                                 4.0, 5.0,
                                 9.0, 8.0,
                                 8.0, 9.0)
    println ("v = " + v)
    println ("----------------------------------------------------")

    for (s <- 0 to 4) {                         // test with different random streams
        banner ("KMeansClustering for stream s = " + s)
        val cl = new KMeansClustering (v, 3, s)                 
	println("Gap: " + cl.gap())	
    } // for


} // KMeansClusteringTest object

//:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** The 'GapStatisticTest' object is used to test the estimate of a gap statistic
 *  using the fully itterated process.
 *  > run-main scalation.analytics.GapStatisticTest
 */
 object GapStatisticTest extends App
 {
	import math.log
	val FILE_NAME  = "chicks.csv"									//or whatever CSV file contains your data
	val file       = new File(FILE_NAME.substring(0,FILE_NAME.indexOf(".")) + "Output.csv")		//for recording the results of the 10 iterations
	val file2      = new File(FILE_NAME.substring(0,FILE_NAME.indexOf(".")) + "GapOut.txt")		//for recording the result of the optimal estimated k
	file.createNewFile()
	file2.createNewFile()
	val LENGTH     = 5										//the # of features the data is measured on
	val SIZE       = 578										//the # of data points
	var wVals      = Array.ofDim[Double](10)							//to store the w() values
	//var wVals  = Array(16.07497015 ,15.04521110 ,14.64738577 ,14.39325503 ,14.19861336 ,13.98923129 ,13.80730824 ,13.73746283 ,13.5972341 ,13.49486803)map(exp(_))
	val data       = io.Source.fromFile(FILE_NAME);							//the source of the data
	var gaps       = Array.ofDim[(Double,Double,Double,Double)](10)					//to store the gap() values
	var dataArray  = Array.ofDim[Double](SIZE,LENGTH)						//to create a matrix of the data
	var i          = 0
	for(line <-data.getLines.drop(1)){								//skip the 1st line of the csv file which is usually a header
		 val cols = line.split(",").map(_.trim)							//tokenize each line of the csv file
		 for(j <- 1 to LENGTH-1){								//skip the first column which is the row name
		       cols(j) = cols(j) replaceAll ("\"","")						//can only use floating point numbers
		       cols(j) = cols(j) replaceAll ("c","")						//" "
  		       if(cols(j) != "NA") dataArray(i)(j-1)=cols(j).toDouble				//" " 
		       else dataArray(i)(j-1)=0
		 } // for
		 //println("")
		 i=i+1
	} // 
	val dataMatrix = new MatrixD(dataArray)
	
	val writer     = new CSVWriter(new FileWriter(file), ',')
	val fileWriter = new FileWriter(file2)

	for(i <- 1 to 10){//for k = 1...10
	      	    val s = (System.currentTimeMillis % 1000).toInt
	            val cl = new KMeansClustering(dataMatrix, i, s)
		    println(s"new random seed: $s")
		    cl.cluster()
		    wVals(i-1) = cl.w()
		    
		    //print(s"wVals(i-1) : ${wVals(i-1)} ")
		    gaps(i-1)  = cl.gap()
		    //print(s"gaps(i-1) : ${gaps(i-1)} ")
		    val entries = Array(log(wVals(i-1)).toString(),gaps(i-1)._3.toString(),
		    gaps(i-1)._1.toString(),gaps(i-1)._2.toString())
		    writer.writeNext(entries)
		    //wVals(i-1) : within cluster sum of squares i.e. - W_{k}
		    //gaps._1 : Gap_{k}
		    //gaps._2 : sk
		    //gaps._3 : estimated expected value log(w_k)
		    //gaps._4 : observed value log(w_k)
	} // for
	writer.close()
	var kHat = 0
	var found = false
	breakable{for(i <- 0 until 9){
	        val (lwki, elwki, gapi, ski) = gaps(i)
		val (lwki1, elwki1, gapi1, ski1) = gaps(i+1)

/* 		if(gaps(i)._1 >= gaps(i+1)._1-gaps(i+1)._2){
	      		 println(s"${i+1} is optimal k")
			 fileWriter.write(Integer.toString(i+1));
			 fileWriter.close();
			 found = true
			 break */
		println(s" gapi: ${gapi}, gaps(i): ${gaps(i)}, gapi1: ${gapi1}, gaps(i+1): ${gaps(i+1)}")
		if(gapi >= gapi1/*-ski1*/){
	      		 println(s"${i+1} is optimal k")
			 fileWriter.write(Integer.toString(i+1));
			 fileWriter.close();
			 found = true
			 break
	        } // if 
	      
	} // for
	} // breakable
	if( !found ) println("Not enough sample cluster sizes to determine optimum")
	for(i <- gaps) println(i)
 } // GapStatisticTest

object KMeansGapTest extends App
{
	
	val FILE_NAME  = "chicks.csv"									//or whatever CSV file contains your data
	val file       = new File(FILE_NAME.substring(0,FILE_NAME.indexOf(".")) + "Output.csv")		//for recording the results of the 10 iterations
	val file2      = new File(FILE_NAME.substring(0,FILE_NAME.indexOf(".")) + "GapOut.txt")		//for recording the result of the optimal estimated k
	
	val LENGTH     = 5										//the # of features the data is measured on
	val SIZE       = 578										//the # of data points
	
	val data       = io.Source.fromFile(FILE_NAME);							//the source of the data

	var dataArray  = Array.ofDim[Double](SIZE,LENGTH)						//to create a matrix of the data
	var i          = 0
	for(line <-data.getLines.drop(1)){								//skip the 1st line of the csv file which is usually a header
		 val cols = line.split(",").map(_.trim)							//tokenize each line of the csv file
		 for(j <- 1 to LENGTH-1){								//skip the first column which is the row name
		       cols(j) = cols(j) replaceAll ("\"","")						//can only use floating point numbers
		       cols(j) = cols(j) replaceAll ("c","")						//" "
  		       if(cols(j) != "NA") dataArray(i)(j-1)=cols(j).toDouble				//" " 
		       else dataArray(i)(j-1)=0
		 } // for
		 //println("")
		 i=i+1
	} // 
	val dataMatrix = new MatrixD(dataArray)
	var clus = new KMeansClustering(dataMatrix,3,(System.currentTimeMillis % 1000).toInt)
	print(clus.cluster())
	
}//KMeansGapTest
